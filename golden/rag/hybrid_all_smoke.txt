ðŸ“„ Vector Memory System initialized with SQLite backend
DEBUG EXECUTOR: Loaded 0 functions: []
ðŸ”§ set_default_model: Setting default model to 'simulated'
ðŸ”§ LlmAdapter: Setting default model to 'simulated'
âœ… set_default_model: Default model updated successfully
ðŸ§  memory_index.ingest: Ingesting 2 paths into vector memory index
ðŸ“„ Ingested: README.md (doc_id: 1, embedding_dim: 128)
ðŸ“„ Ingested: ROADMAP.md (doc_id: 2, embedding_dim: 128)
âœ… memory_index.ingest: Successfully ingested 2 documents
ingested=
2
[{"content":"![Lexon](assets/lexon-wordmark.svg)\n\n## Lexon v1.0.0-rc.1\n\nA self-contained RC of the Lexon language and tooling: language/runtime, CLI, samples, Tree-sitter grammar, VS Code extension, and Python binding.\n\n### Why Lexon (quick)\n- Orchestrate LLM + data as first-class language features (async/await, parallel/merge/fallback/ensemble).\n- Built-in reliability: validation (`ask_safe`) with confidence scoring; sessions/RAG Lite.\n- Deterministic artifacts: multioutput (text + multiple files/binaries) ","path":"README.md","hybrid_score":0.37798595428466797,"vector_score":0.11140851676464081,"text_score":1.0,"doc_id":1},{"content":"## Roadmap Snapshot\n\nThis roadmap reflects the v1.0.0-rc.1 scope and is the authoritative plan for this bundle.\n\n### Implemented in v1.0.0-rc.1 (current)\n- Core: `typeof`, `Ok`, `Error`, `is_ok`, `is_error`, `unwrap`.\n- LLM orchestration: `ask`, `ask_parallel`, `ask_merge`, `ask_with_fallback`, `ask_ensemble`, `ask_safe`.\n- Providers (real): OpenAI, Anthropic, Google Gemini; plus Generic Providers via `configure_provider` (HuggingFace, Ollama, Custom).\n- Antiâ€‘hallucination: `ask_safe` with confi","path":"ROADMAP.md","hybrid_score":0.36606574058532715,"vector_score":0.09437960386276245,"text_score":1.0,"doc_id":2}]
