// Lexon CLI (RC)

use clap::{Args, Parser as ClapParser};
use lexc::executor::{ExecutionEnvironment, ExecutorConfig};
use lexc::lex_executor::{HybridExecutor, LexExecutor};
use lexc::lexir::LexProgram;
use lexc::linter as lexlint;
use lexc::optimizer::{Optimization, Optimizer, OptimizerConfig};
use lexc::runtime::RuntimeConfig;
// tracing is optional in CLI; use a shim to avoid hard dependency
#[allow(dead_code)]
mod trace_shim {
    pub fn info_span(_s: &str) {}
}
use lexc::{hir_builder, hir_to_lexir};
use std::fs;
use std::path::PathBuf;
use std::time::Instant;
use tokio::runtime::Runtime as TokioRuntime;
use tree_sitter::Parser;

// Link to the function generated by tree-sitter for Lexon
extern "C" {
    fn tree_sitter_lexon() -> tree_sitter::Language;
}

/// Args of the `compile` subcommand
#[derive(Args, Debug, Clone)]
struct CompileArgs {
    /// Input Lexon file (.lx)
    #[arg(required_unless_present = "load_ir")]
    input_file: Option<PathBuf>,

    /// Syntax/semantic check only
    #[arg(long, short = 'c')]
    check: bool,

    /// Emit JSON Schema of the first schema found
    #[arg(long)]
    emit_json_schema: bool,

    /// Emit code to a target (experimental)
    #[arg(long, value_name = "TARGET")]
    emit: Option<EmitTarget>,

    /// Execute after compile
    #[arg(long, short = 'r')]
    run: bool,

    /// Optimize (-O)
    #[arg(long, short = 'O')]
    optimize: bool,

    /// Enable all available optimizations
    #[arg(long)]
    all_opts: bool,

    /// Verbose
    #[arg(long, short = 'v')]
    verbose: bool,

    /// Export LexIR to JSON
    #[arg(long, value_name = "FILE")]
    export_ir: Option<PathBuf>,

    /// Load LexIR from JSON and execute
    #[arg(long, value_name = "FILE")]
    load_ir: Option<PathBuf>,

    /// LLM model
    #[arg(long, value_name = "MODEL")]
    llm_model: Option<String>,

    /// LLM API key
    #[arg(long, value_name = "KEY")]
    llm_api_key: Option<String>,

    /// Memory path for contextual memory
    #[arg(long, value_name = "PATH")]
    memory_path: Option<String>,

    /// Timeout (ms)
    #[arg(long, value_name = "MS")]
    timeout: Option<u64>,

    /// Run in async mode
    #[arg(long)]
    async_mode: bool,

    /// Benchmark timings
    #[arg(long)]
    bench: bool,

    /// Allow executing external commands (unsafe)
    #[arg(long, default_value_t = false)]
    allow_exec: bool,

    /// Restrict file I/O to this workspace directory (sandbox)
    #[arg(long, value_name = "PATH")]
    workspace: Option<PathBuf>,
}

/// Target languages for emit
#[derive(Copy, Clone, PartialEq, Eq, PartialOrd, Ord, clap::ValueEnum, Debug)]
enum EmitTarget {
    #[value(name = "lexir")]
    LexIr,
    #[value(name = "python")]
    Python,
}

/// Benchmark metrics
#[derive(Debug)]
struct BenchResult {
    compile_ms: f64,
    exec_ms: Option<f64>,
}

fn compile_once(args: &CompileArgs, rt: &TokioRuntime) -> Result<BenchResult, String> {
    let start = Instant::now();
    let exec_ms = compile_flow(args, rt)?;
    Ok(BenchResult {
        compile_ms: start.elapsed().as_secs_f64() * 1000.0,
        exec_ms,
    })
}

#[derive(Args, Debug, Clone)]
struct BenchArgs {
    input_file: PathBuf,
    #[arg(long, default_value_t = 10)]
    iterations: u32,
    #[arg(long, default_value_t = 1)]
    warmup: u32,
    #[arg(long, short = 'r')]
    run: bool,
    #[arg(long, short = 'O')]
    optimize: bool,
    #[arg(long)]
    all_opts: bool,
    #[arg(long)]
    async_mode: bool,
    #[arg(long, short = 'v')]
    verbose: bool,
    #[arg(long, value_name = "PATH")]
    memory_path: Option<String>,
}

#[derive(ClapParser, Debug)]
#[command(author, version, about)]
enum Cli {
    Compile(CompileArgs),
    Bench(BenchArgs),
    Lint(LintArgs),
    Run(RunArgs),
    Config(ConfigArgs),
    New(NewArgs),
}

#[derive(Args, Debug, Clone)]
struct RunArgs {
    input_file: PathBuf,
    #[arg(long, short = 'v')]
    verbose: bool,
}

#[derive(Args, Debug, Clone)]
struct ConfigArgs {
    #[arg(long)]
    json: bool,
}

#[derive(Args, Debug, Clone)]
struct NewArgs {
    dir: PathBuf,
    #[arg(long, default_value_t = true)]
    sample: bool,
}

fn main() {
    // Load external plugins if present
    let default_dir = std::path::Path::new("plugins");
    if let Ok(custom) = std::env::var("LEXC_PLUGINS_DIR") {
        lexc::plugin::load_plugins_from_dir(std::path::Path::new(&custom));
    } else {
        lexc::plugin::load_plugins_from_dir(default_dir);
    }

    let cli = Cli::parse();
    match cli {
        Cli::Compile(args) => compile_command(args),
        Cli::Bench(bargs) => bench_command(bargs),
        Cli::Lint(largs) => lint_command(largs),
        Cli::Run(rargs) => run_command(rargs),
        Cli::Config(cargs) => config_command(cargs),
        Cli::New(nargs) => new_command(nargs),
    }
}

fn bench_command(bargs: BenchArgs) {
    let rt = TokioRuntime::new().expect("Tokio runtime");
    let mut compile_times = Vec::new();
    let mut exec_times = Vec::new();
    let total = bargs.warmup + bargs.iterations;
    for i in 0..total {
        let args = CompileArgs {
            input_file: Some(bargs.input_file.clone()),
            check: false,
            emit_json_schema: false,
            emit: None,
            run: bargs.run,
            optimize: bargs.optimize,
            all_opts: bargs.all_opts,
            verbose: bargs.verbose,
            export_ir: None,
            load_ir: None,
            llm_model: None,
            llm_api_key: None,
            memory_path: bargs.memory_path.clone(),
            timeout: None,
            async_mode: bargs.async_mode,
            bench: true,
            allow_exec: false,
            workspace: None,
        };
        let res = compile_once(&args, &rt);
        match res {
            Ok(m) => {
                if i >= bargs.warmup {
                    compile_times.push(m.compile_ms);
                    if let Some(e) = m.exec_ms {
                        exec_times.push(e);
                    }
                }
            }
            Err(e) => {
                eprintln!("Error in iteration {}: {}", i, e);
                return;
            }
        }
    }
    // Statistics
    fn mean(v: &[f64]) -> f64 {
        if v.is_empty() {
            0.0
        } else {
            v.iter().sum::<f64>() / v.len() as f64
        }
    }
    fn median(mut v: Vec<f64>) -> f64 {
        if v.is_empty() {
            0.0
        } else {
            v.sort_by(|a, b| a.partial_cmp(b).unwrap());
            let n = v.len();
            if n % 2 == 0 {
                (v[n / 2 - 1] + v[n / 2]) / 2.0
            } else {
                v[n / 2]
            }
        }
    }
    fn std(v: &[f64]) -> f64 {
        if v.len() <= 1 {
            0.0
        } else {
            let m = mean(v);
            (v.iter().map(|x| (x - m).powi(2)).sum::<f64>() / (v.len() as f64 - 1.0)).sqrt()
        }
    }
    println!("=== Benchmark Summary ===");
    if !compile_times.is_empty() {
        println!(
            "Compile: mean {:.2} ms | median {:.2} ms | min {:.2} | max {:.2} | std {:.2}",
            mean(&compile_times),
            median(compile_times.clone()),
            compile_times.iter().cloned().fold(f64::INFINITY, f64::min),
            compile_times
                .iter()
                .cloned()
                .fold(f64::NEG_INFINITY, f64::max),
            std(&compile_times)
        );
    }
    if !exec_times.is_empty() {
        println!(
            "Execute: mean {:.2} ms | median {:.2} ms | min {:.2} | max {:.2} | std {:.2}",
            mean(&exec_times),
            median(exec_times.clone()),
            exec_times.iter().cloned().fold(f64::INFINITY, f64::min),
            exec_times.iter().cloned().fold(f64::NEG_INFINITY, f64::max),
            std(&exec_times)
        );
    }
}

fn compile_command(args: CompileArgs) {
    let rt = TokioRuntime::new().expect("Tokio runtime");
    if let Err(e) = compile_flow(&args, &rt) {
        eprintln!("Error: {}", e);
        std::process::exit(1);
    }
}

#[derive(Args, Debug, Clone)]
struct LintArgs {
    /// One or more .lx files to lint
    #[arg(required = true)]
    files: Vec<PathBuf>,
    /// Verbose output
    #[arg(long, short = 'v')]
    verbose: bool,
    /// Exit non-zero if warnings are found
    #[arg(long)]
    strict: bool,
}

fn lint_command(largs: LintArgs) {
    let mut had_issues = false;
    let mut had_warnings = false;
    for file in &largs.files {
        match fs::read_to_string(file) {
            Ok(source) => {
                // Parse CST → HIR using tree-sitter
                let mut parser = Parser::new();
                let language = unsafe { tree_sitter_lexon() };
                if let Err(e) = parser.set_language(&language) {
                    eprintln!("Set language error for {}: {}", file.display(), e);
                    had_issues = true;
                    continue;
                }
                let tree = match parser.parse(&source, None) {
                    Some(t) => t,
                    None => {
                        eprintln!("Parse error in {}", file.display());
                        had_issues = true;
                        continue;
                    }
                };
                let hir_nodes =
                    match lexc::hir_builder::build_hir_from_cst(tree.root_node(), &source) {
                        Ok(nodes) => nodes,
                        Err(e) => {
                            eprintln!("HIR error in {}: {:?}", file.display(), e);
                            had_issues = true;
                            continue;
                        }
                    };
                let res = lexlint::lint_hir(&hir_nodes);
                if largs.verbose {
                    println!("Linting {}:", file.display());
                }
                if res.warnings.is_empty() && res.errors.is_empty() {
                    if largs.verbose {
                        println!("  ✅ No linting issues found");
                    }
                } else {
                    had_issues = true;
                    if !res.warnings.is_empty() {
                        had_warnings = true;
                    }
                    for w in res.warnings {
                        match w {
                            lexlint::LintWarning::MissingAwait {
                                function_name,
                                line,
                                message,
                            } => {
                                println!(
                                    "  Warning [{}:{}]: {} — {}",
                                    file.display(),
                                    line,
                                    function_name,
                                    message
                                );
                            }
                            lexlint::LintWarning::BlockingIoInAsync {
                                operation,
                                line,
                                message,
                            } => {
                                println!(
                                    "  Warning [{}:{}]: {} — {}",
                                    file.display(),
                                    line,
                                    operation,
                                    message
                                );
                            }
                            lexlint::LintWarning::AsyncFunctionNotAwaited {
                                function_name,
                                line,
                                message,
                            } => {
                                println!(
                                    "  Warning [{}:{}]: {} — {}",
                                    file.display(),
                                    line,
                                    function_name,
                                    message
                                );
                            }
                            lexlint::LintWarning::SyncCallInAsyncContext {
                                function_name,
                                line,
                                message,
                            } => {
                                println!(
                                    "  Warning [{}:{}]: {} — {}",
                                    file.display(),
                                    line,
                                    function_name,
                                    message
                                );
                            }
                        }
                    }
                    for e in res.errors {
                        println!("  Error: {}", e);
                    }
                }
            }
            Err(e) => {
                eprintln!("Failed to read {}: {}", file.display(), e);
                had_issues = true;
            }
        }
    }
    if largs.strict && had_warnings {
        std::process::exit(2);
    }
    if had_issues {
        std::process::exit(2);
    }
}

fn run_command(rargs: RunArgs) {
    let rt = TokioRuntime::new().expect("Tokio runtime");
    let args = CompileArgs {
        input_file: Some(rargs.input_file),
        check: false,
        emit_json_schema: false,
        emit: None,
        run: true,
        optimize: false,
        all_opts: false,
        verbose: rargs.verbose,
        export_ir: None,
        load_ir: None,
        llm_model: None,
        llm_api_key: None,
        memory_path: None,
        timeout: None,
        async_mode: false,
        bench: false,
        allow_exec: false,
        workspace: None,
    };
    if let Err(e) = compile_flow(&args, &rt) {
        eprintln!("Error: {}", e);
        std::process::exit(1);
    }
}

fn config_command(cargs: ConfigArgs) {
    // Print effective runtime/env config
    let mut map = serde_json::Map::new();
    map.insert(
        "routing_policy".to_string(),
        serde_json::Value::String(
            std::env::var("LEXON_ROUTING_POLICY").unwrap_or_else(|_| "(unset)".to_string()),
        ),
    );
    map.insert(
        "ab_models".to_string(),
        serde_json::Value::String(
            std::env::var("LEXON_AB_MODELS").unwrap_or_else(|_| "(unset)".to_string()),
        ),
    );
    map.insert(
        "provider_health".to_string(),
        serde_json::Value::String(
            std::env::var("LEXON_PROVIDER_HEALTH").unwrap_or_else(|_| "(unset)".to_string()),
        ),
    );
    map.insert(
        "llm_retries".to_string(),
        serde_json::Value::String(
            std::env::var("LEXON_LLM_RETRIES").unwrap_or_else(|_| "(unset)".to_string()),
        ),
    );
    map.insert(
        "llm_backoff_ms".to_string(),
        serde_json::Value::String(
            std::env::var("LEXON_LLM_BACKOFF_MS").unwrap_or_else(|_| "(unset)".to_string()),
        ),
    );
    map.insert(
        "canary_model".to_string(),
        serde_json::Value::String(
            std::env::var("LEXON_CANARY_MODEL").unwrap_or_else(|_| "(unset)".to_string()),
        ),
    );
    map.insert(
        "canary_percent".to_string(),
        serde_json::Value::String(
            std::env::var("LEXON_CANARY_PERCENT").unwrap_or_else(|_| "(unset)".to_string()),
        ),
    );
    map.insert(
        "provider_budgets".to_string(),
        serde_json::Value::String(
            std::env::var("LEXON_PROVIDER_BUDGETS").unwrap_or_else(|_| "(unset)".to_string()),
        ),
    );
    map.insert(
        "provider_capacity".to_string(),
        serde_json::Value::String(
            std::env::var("LEXON_PROVIDER_CAPACITY").unwrap_or_else(|_| "(unset)".to_string()),
        ),
    );
    map.insert(
        "routing_weights".to_string(),
        serde_json::Value::String(
            std::env::var("LEXON_ROUTING_WEIGHTS").unwrap_or_else(|_| "(unset)".to_string()),
        ),
    );
    map.insert(
        "quality_schema_enforce".to_string(),
        serde_json::Value::String(
            std::env::var("LEXON_QUALITY_SCHEMA_ENFORCE").unwrap_or_else(|_| "(unset)".to_string()),
        ),
    );
    map.insert(
        "quality_pii_block".to_string(),
        serde_json::Value::String(
            std::env::var("LEXON_QUALITY_PII_BLOCK").unwrap_or_else(|_| "(unset)".to_string()),
        ),
    );
    map.insert(
        "vector_backend".to_string(),
        serde_json::Value::String(
            std::env::var("LEXON_VECTOR_BACKEND").unwrap_or_else(|_| "(unset)".to_string()),
        ),
    );
    map.insert(
        "qdrant_url".to_string(),
        serde_json::Value::String(
            std::env::var("LEXON_QDRANT_URL").unwrap_or_else(|_| "(unset)".to_string()),
        ),
    );
    map.insert(
        "qdrant_collection".to_string(),
        serde_json::Value::String(
            std::env::var("LEXON_QDRANT_COLLECTION").unwrap_or_else(|_| "(unset)".to_string()),
        ),
    );
    map.insert(
        "qdrant_throttle_ms".to_string(),
        serde_json::Value::String(
            std::env::var("LEXON_QDRANT_THROTTLE_MS").unwrap_or_else(|_| "(unset)".to_string()),
        ),
    );
    if cargs.json {
        println!("{}", serde_json::Value::Object(map).to_string());
    } else {
        println!(
            "LEXON effective config:\n{}",
            serde_json::to_string_pretty(&serde_json::Value::Object(map)).unwrap()
        );
    }
}

fn new_command(nargs: NewArgs) {
    let root = &nargs.dir;
    if let Err(e) = std::fs::create_dir_all(root) {
        eprintln!("Error: {}", e);
        std::process::exit(1);
    }
    let samples = root.join("samples");
    let src = root.join("src");
    let _ = std::fs::create_dir_all(&samples);
    let _ = std::fs::create_dir_all(&src);

    // lexon.toml
    let toml = r#"# lexon.toml - project configuration
[providers]
default = "openai"

[routing]
policy = "auto"
"#;
    let _ = std::fs::write(root.join("lexon.toml"), toml);

    // README
    let readme = r#"# Lexon Project

This is a minimal Lexon project scaffold.

## Quick start
lexc-cli run samples/00-hello-lexon.lx
"#;
    let _ = std::fs::write(root.join("README.md"), readme);

    if nargs.sample {
        let hello = r#"// 00-hello-lexon.lx — minimal hello
let greeting: string = "Hello Lexon!";
print(greeting);
let answer: string = ask {
  model: simulated;
  user: "Say 'LEXON OK' exactly";
};
print(answer);
"#;
        let _ = std::fs::write(samples.join("00-hello-lexon.lx"), hello);
    }

    println!("✅ Created Lexon project at {}", root.display());
}

/// Compile and optionally run; returns exec_ms if executed.
fn compile_flow(args: &CompileArgs, rt: &TokioRuntime) -> Result<Option<f64>, String> {
    // 0. Init tracing (no-op if feature disabled or env unset)
    let _ = lexc::telemetry::init_tracing();
    trace_shim::info_span("compile_flow");

    // 1. Obtain LexProgram
    let mut program: LexProgram;
    if let Some(ir_path) = &args.load_ir {
        let json = fs::read_to_string(ir_path)
            .map_err(|e| format!("Reading {}: {}", ir_path.display(), e))?;
        program = LexProgram::from_json(&json).map_err(|e| format!("Parsing IR JSON: {}", e))?;
    } else {
        let input = args
            .input_file
            .as_ref()
            .ok_or_else(|| "--input-file is required".to_string())?;
        // Load entry file and recursively load imports (multi-file modules)
        fn parse_file_to_hir(path: &std::path::Path) -> Result<Vec<lexc::hir::HirNode>, String> {
            let source = fs::read_to_string(path)
                .map_err(|e| format!("Reading {}: {}", path.display(), e))?;
            let mut parser = Parser::new();
            let language = unsafe { tree_sitter_lexon() };
            parser
                .set_language(&language)
                .map_err(|e| format!("Parser config error: {}", e))?;
            let tree = parser
                .parse(&source, None)
                .ok_or_else(|| "Parse error".to_string())?;
            let hir_nodes = hir_builder::build_hir_from_cst(tree.root_node(), &source)
                .map_err(|e| format!("HIR error: {:?}", e))?;
            Ok(hir_nodes)
        }

        fn collect_imports_rec(
            start: &std::path::Path,
            visited: &mut std::collections::HashSet<String>,
        ) -> Result<Vec<lexc::hir::HirNode>, String> {
            let abs = std::fs::canonicalize(start).unwrap_or(start.to_path_buf());
            let key = abs.to_string_lossy().to_string();
            if !visited.insert(key) {
                return Ok(Vec::new());
            }
            let mut all = parse_file_to_hir(&abs)?;
            // Find imports and load them
            use lexc::hir::HirNode;
            let dir = abs.parent().unwrap_or(std::path::Path::new("."));
            let roots_env = std::env::var("LEXON_MODULE_ROOTS").unwrap_or_default();
            let extra_roots: Vec<std::path::PathBuf> = roots_env
                .split(':')
                .filter(|s| !s.is_empty())
                .map(|s| std::path::PathBuf::from(s))
                .collect();
            let mut to_load: Vec<std::path::PathBuf> = Vec::new();
            for node in &all {
                if let HirNode::ImportDeclaration(import) = node {
                    if !import.path.is_empty() {
                        let rel = import.path.join("/");
                        let rel_file = rel.clone() + ".lx";
                        // Candidate paths: <rel>.lx, <rel>/index.lx, <rel>/mod.lx in current dir and extra roots
                        let mut candidates: Vec<std::path::PathBuf> = Vec::new();
                        // current dir
                        candidates.push(dir.join(&rel_file));
                        candidates.push(dir.join(&rel).join("index.lx"));
                        candidates.push(dir.join(&rel).join("mod.lx"));
                        // extra roots
                        for r in &extra_roots {
                            candidates.push(r.join(&rel_file));
                            candidates.push(r.join(&rel).join("index.lx"));
                            candidates.push(r.join(&rel).join("mod.lx"));
                        }
                        let chosen = candidates.iter().find(|p| p.exists()).cloned();
                        if let Some(p) = chosen {
                            to_load.push(p);
                        } else {
                            // Better diagnostics: list searched candidates and hint about LEXON_MODULE_ROOTS
                            let mut msg = String::new();
                            msg.push_str(&format!("Import not found: '{}'\n", rel));
                            msg.push_str("Searched candidate files:\n");
                            for c in &candidates {
                                msg.push_str(&format!(" - {}\n", c.display()));
                            }
                            let roots_hint = if extra_roots.is_empty() {
                                "(no LEXON_MODULE_ROOTS set)".to_string()
                            } else {
                                format!(
                                    "LEXON_MODULE_ROOTS={}",
                                    std::env::var("LEXON_MODULE_ROOTS").unwrap_or_default()
                                )
                            };
                            msg.push_str(&format!(
                                "Module search roots: {} and {}\n",
                                dir.display(),
                                roots_hint
                            ));
                            msg.push_str("Hint: set LEXON_MODULE_ROOTS to additional module directories, e.g. export LEXON_MODULE_ROOTS=modules:shared\n");
                            return Err(msg);
                        }
                    }
                }
            }
            for p in to_load {
                let mut more = collect_imports_rec(&p, visited)?;
                all.append(&mut more);
            }
            Ok(all)
        }

        let mut visited = std::collections::HashSet::new();
        let hir_nodes = collect_imports_rec(input, &mut visited)?;

        // Sandbox checks on HIR
        enforce_sandbox(&hir_nodes, args).map_err(|e| format!("Sandbox: {}", e))?;
        if args.check {
            if args.verbose {
                println!("Check OK ({} nodes)", hir_nodes.len());
            }
            return Ok(None);
        }
        program = hir_to_lexir::convert_hir_to_lexir(&hir_nodes)
            .map_err(|e| format!("HIR→LexIR error: {:?}", e))?;
    }

    // 2. Optimize
    if args.optimize || args.all_opts {
        let mut cfg = OptimizerConfig {
            verbose: args.verbose,
            ..OptimizerConfig::default()
        };
        if args.all_opts {
            cfg.enabled_optimizations = vec![
                Optimization::DeadCodeElimination,
                Optimization::ConstantPropagation,
                Optimization::ConstantFolding,
                Optimization::DataOperationFusion,
                Optimization::RedundantAssignmentElimination,
                Optimization::InlineFunction,
            ];
        }
        let opt = Optimizer::new(cfg);
        opt.optimize(&mut program)
            .map_err(|e| format!("Optimize: {:?}", e))?;
    }

    // 3. Export IR
    if let Some(path) = &args.export_ir {
        let json = program
            .to_json()
            .map_err(|e| format!("Serializar IR: {}", e))?;
        fs::write(path, json).map_err(|e| format!("Writing {}: {}", path.display(), e))?;
    }

    // 4. Execute
    if args.run {
        let t0 = Instant::now();
        if args.async_mode {
            // Build the runtime configuration before entering the async context
            let mut cfg = RuntimeConfig {
                verbose: args.verbose,
                memory_path: args.memory_path.clone(),
                timeout_ms: args.timeout,
                ..RuntimeConfig::default()
            };
            if let Some(m) = &args.llm_model {
                cfg.llm_model = Some(m.clone());
            }
            if let Some(k) = &args.llm_api_key {
                cfg.llm_api_key = Some(k.clone());
            }

            // Execute within the existing Tokio runtime
            let exec_res = rt.block_on(async {
                let mut runtime = lexc::Runtime::new(cfg);
                runtime
                    .execute_program(&program)
                    .await
                    .map_err(|e| format!("{:?}", e))
            });

            exec_res?;
        } else {
            let mut executor = HybridExecutor::Sync(ExecutionEnvironment::new(ExecutorConfig {
                memory_path: args.memory_path.clone(),
                verbose: args.verbose,
                llm_model: args.llm_model.clone(),
                use_new_llm_architecture: true, // Use new architecture by default
                llm_mode: Some("auto".to_string()), // Automatic mode
            }));

            let res = rt.block_on(async { executor.execute_program_generic(&program).await });
            res.map_err(|e| format!("Execution: {}", e))?;
        }

        Ok(Some(t0.elapsed().as_secs_f64() * 1000.0))
    } else {
        Ok(None)
    }
}

fn enforce_sandbox(hir_nodes: &[lexc::hir::HirNode], args: &CompileArgs) -> Result<(), String> {
    use lexc::hir::HirNode;
    // Disallow execute() unless explicitly allowed
    fn visit(node: &HirNode, allow_exec: bool, ws: &Option<PathBuf>, err: &mut Option<String>) {
        if err.is_some() {
            return;
        }
        match node {
            HirNode::FunctionCall(fc) => {
                let name = fc.function.as_str();
                if name == "execute" && !allow_exec {
                    *err = Some(
                        "execute() is disabled by default. Use --allow-exec to enable.".to_string(),
                    );
                    return;
                }
                // Basic path checks for read/write when literal arg is absolute and no workspace set
                if (name == "read_file"
                    || name == "write_file"
                    || name == "save_file"
                    || name == "load_file")
                    && ws.is_none()
                {
                    if let Some(HirNode::Literal(lexc::hir::HirLiteral::String(path))) =
                        fc.args.first()
                    {
                        if path.starts_with('/') {
                            *err = Some(
                                "Absolute paths are blocked without --workspace sandbox"
                                    .to_string(),
                            );
                            return;
                        }
                    }
                }
                for a in &fc.args {
                    visit(a, allow_exec, ws, err);
                    if err.is_some() {
                        return;
                    }
                }
            }
            HirNode::Assignment(a) => visit(&a.right, allow_exec, ws, err),
            HirNode::If(i) => {
                visit(&i.condition, allow_exec, ws, err);
                for n in &i.then_body {
                    visit(n, allow_exec, ws, err);
                }
                if let Some(eb) = &i.else_body {
                    for n in eb {
                        visit(n, allow_exec, ws, err);
                    }
                }
            }
            HirNode::While(w) => {
                visit(&w.condition, allow_exec, ws, err);
                for n in &w.body {
                    visit(n, allow_exec, ws, err);
                }
            }
            HirNode::ForIn(f) => {
                visit(&f.iterable, allow_exec, ws, err);
                for n in &f.body {
                    visit(n, allow_exec, ws, err);
                }
            }
            HirNode::Binary(b) => {
                visit(&b.left, allow_exec, ws, err);
                visit(&b.right, allow_exec, ws, err);
            }
            HirNode::VariableDeclaration(v) => visit(&v.value, allow_exec, ws, err),
            HirNode::Await(a) => visit(&a.expression, allow_exec, ws, err),
            HirNode::Match(m) => {
                visit(&m.value, allow_exec, ws, err);
                for arm in &m.arms {
                    visit(&arm.pattern, allow_exec, ws, err);
                    for n in &arm.body {
                        visit(n, allow_exec, ws, err);
                    }
                }
            }
            HirNode::MethodCall(mc) => {
                for a in &mc.args {
                    visit(a, allow_exec, ws, err);
                }
            }
            HirNode::FunctionDefinition(fd) => {
                for n in &fd.body {
                    visit(n, allow_exec, ws, err);
                }
            }
            // data ops memory ops
            HirNode::DataLoad(_)
            | HirNode::DataFilter(_)
            | HirNode::DataSelect(_)
            | HirNode::DataTake(_)
            | HirNode::DataExport(_)
            | HirNode::MemoryLoad(_)
            | HirNode::MemoryStore(_) => {}
            // leafs
            HirNode::Literal(_)
            | HirNode::Identifier(_)
            | HirNode::Break
            | HirNode::Continue
            | HirNode::Return(_)
            | HirNode::Ask(_)
            | HirNode::AskSafe(_)
            | HirNode::TypeOf(_)
            | HirNode::SchemaDefinition(_)
            | HirNode::ModuleDeclaration(_)
            | HirNode::ImportDeclaration(_)
            | HirNode::TraitDefinition(_)
            | HirNode::ImplBlock(_) => {}
        }
    }
    let mut err: Option<String> = None;
    for n in hir_nodes {
        visit(n, args.allow_exec, &args.workspace, &mut err);
        if err.is_some() {
            break;
        }
    }
    if let Some(e) = err {
        return Err(e);
    }
    Ok(())
}
