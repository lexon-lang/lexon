# ðŸ”§ Lexon Configuration File
# =============================
# Complete configuration for Lexon projects (Sprint B)

# Sprint B: Project and modules configuration
[project]
name = "lexon-project"
version = "1.0.0"
description = "A Lexon DSL project"
modules_dir = "modules"
output_dir = "target"
include = ["*.lx", "modules/**/*.lx", "data/**/*"]
exclude = ["target/**/*", "*.tmp", "*.log"]

# LLM system configuration
[system]
default_provider = "simulated"
fallback_provider = "simulated"
fallback_model = "simulated"
cache_enabled = true
retry_attempts = 3
timeout_default = 30

# Sprint B: Memory configuration
[memory]
storage_path = ".lexon/memory"
max_entries = 10000
cleanup_interval = "24h"

# Sprint B: Validation configuration
[validation]
default_strategy = "basic"
confidence_threshold = 0.8
max_attempts = 3

# Sprint B: Logging configuration
[logging]
level = "info"
output = "stdout"
file_path = ".lexon/logs/lexon.log"

# LLM providers configuration
[providers.openai]
name = "OpenAI"
base_url = "https://api.openai.com/v1"
auth_header = "Authorization"
auth_format = "Bearer {api_key}"
api_key_env = "OPENAI_API_KEY"
default_model = "gpt-4"
timeout = 60

[providers.openai.endpoints]
chat = "chat/completions"
completions = "completions"

[providers.openai.models]
"gpt-4" = { max_tokens = 8192, cost_per_1k = 0.03 }
"gpt-4-turbo" = { max_tokens = 128000, cost_per_1k = 0.01 }
"gpt-3.5-turbo" = { max_tokens = 4096, cost_per_1k = 0.002 }

[providers.anthropic]
name = "Anthropic"
base_url = "https://api.anthropic.com/v1"
auth_header = "x-api-key"
auth_format = "{api_key}"
api_key_env = "ANTHROPIC_API_KEY"
default_model = "claude-3-5-sonnet-20241022"
timeout = 60

[providers.anthropic.headers]
"anthropic-version" = "2023-06-01"
"content-type" = "application/json"

[providers.anthropic.endpoints]
messages = "messages"

[providers.anthropic.models]
"claude-3-5-sonnet-20241022" = { max_tokens = 200000, cost_per_1k = 0.003 }
"claude-3-5-sonnet-20240620" = { max_tokens = 200000, cost_per_1k = 0.003 }
"claude-3-opus-20240229" = { max_tokens = 200000, cost_per_1k = 0.015 }
"claude-3-haiku-20240307" = { max_tokens = 200000, cost_per_1k = 0.00025 }

[providers.google]
name = "Google"
base_url = "https://generativelanguage.googleapis.com/v1beta"
auth_format = "key={api_key}"
api_key_env = "GOOGLE_API_KEY"
default_model = "gemini-2.5-pro"
timeout = 45

[providers.google.endpoints]
generate = "models/{model}:generateContent"

[providers.google.models]
"gemini-2.5-pro" = { max_tokens = 1000000, cost_per_1k = 0.0035 }
"gemini-2.5-flash" = { max_tokens = 1000000, cost_per_1k = 0.00035 } 